# -*- coding: utf-8 -*-
"""LSTM ON CARLA DATA_sub.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SbTtgy9HjVgWxQN0qhyyvkIjUNMjoVUW
"""

# !git clone https://github.com/nachiket92/conv-social-pooling.git 
# %cd conv-social-pooling 
# !ls


# from google.colab import drive
# drive.mount('/content/drive')

# !ls "/content/drive/My Drive"
# ! cp -r /content/drive/MyDrive/paper2/data_carla/data_preprocess.py .
# %cd ..

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/data_carla
# %pwd
# %%
import torch 
import torch.nn as nn
from torch import optim
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader

import numpy as np
from tqdm import trange
import random
import model_new as model
import pandas as pd
import matplotlib.pyplot as plt
import pickle
import data_preprocess

from shapely.geometry import Point, Polygon, LineString, LinearRing
from shapely.affinity import affine_transform, rotate
import math

# %%
traj, pos_x_mean, pos_x_std, pos_y_mean, pos_y_std = data_preprocess.get_traj("Location.csv")

# %%
#hold-out test segment
plt.plot(traj[idx][:,0], traj[idx][:,1],'k', label = f"traj_{idx}")
plt.plot(traj[idx][1000:1100,0], traj[idx][1000:1100,1],'r', label = "prediction")
plt.legend()
plt.show()
# %%
test = traj[idx][1000:1100,:]
np.savetxt("toy_example/test_data.csv", test)
# %%
#forecasting on vid=0
idx = 0
obs_len = 40
target_len = 50
#segment the train and val trajs
train_val_idx = [i for i in range(0,1000)] + [i for i in range(1100,traj[idx].shape[0])]
pos_x, pos_y, frame_start, vids = data_preprocess.windowed_dataset2(traj[idx][train_val_idx,:], obs_len+target_len, stride=1)


# %%
#convert to df
df = pd.DataFrame()
df["pos_x"] = pos_x
df["pos_y"] = pos_y
df["frame_start"] = frame_start
df["vid"] = vids

# %%
#remove observed non-moving cars
non_move = []
for i in range(df.shape[0]):
    x_coord_seq = (df["pos_x"].values)[i]
    y_coord_seq = (df["pos_y"].values)[i]
    xy_seq_hist = np.stack((x_coord_seq[:obs_len], y_coord_seq[:obs_len]), axis=-1)
    xy_seq_fut = np.stack((x_coord_seq[obs_len:], y_coord_seq[obs_len:]), axis=-1)
    ls = LineString(xy_seq_hist)
    ls1 = LineString(xy_seq_fut)
    if ls.length < 0.1 or ls1.length < 0.1:
        non_move.append(i)
df1 = df.drop(non_move).reset_index(drop=True)

# %%
#translate and rotate traj
data_preprocess.normalize_traj(df1, obs_len)
# %%
# #get relative distance in place
# for idx in range(df1.shape[0]):  
#     data = df1["normalized_traj"][idx] 
#     traj_len = obs_len+target_len
#     for i in range(traj_len - 1, 0, -1):
#         data[i, :2] = data[i, :2] - data[i - 1, :2]

# %%
plot_idx = 750
# plt.plot((df1["pos_x"].values)[plot_idx], (df1["pos_y"].values)[plot_idx])

plt.plot((df1["normalized_traj"].values)[plot_idx][:,0], (df1["normalized_traj"].values)[plot_idx][:,1])
# %%
## Network Arguments
args = {}
args['input_size'] = 2
args['hidden_size_enc'] = 64
args['hidden_size_dec'] = 64
args['num_layers'] = 1
args["embedding_size"] = 8
args['use_cuda'] = True
args['obs_len'] = obs_len
args['target_len'] = target_len

device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using {device} device")
if device == "cuda":
    print(f"Using all ({torch.cuda.device_count()}) GPUs...")

# %%
#split the dataset 8:1:1
n_sample = df1["normalized_traj"].shape[0]
# data_train = df1["normalized_traj"][:4*n_sample//5]
# # data_val=data[4*len(data)//500+1:4*len(data)//500+100, :, :]
# data_val = df1["normalized_traj"][3*n_sample//5+1:4*n_sample//5]

data_train = pd.concat([df1["normalized_traj"][0:650], df1["normalized_traj"][750:]],axis=0)
data_val = df1["normalized_traj"][650:750]

data_val = data_val.reset_index(drop=True)
data_train = data_train.reset_index(drop=True)


# %%
batch_size = 32
tr = data_preprocess.CarlaDataset2(data_train, t_h = obs_len, t_f = target_len)
val = data_preprocess.CarlaDataset2(data_val, t_h = obs_len, t_f = target_len)

trDataloader = DataLoader(tr, batch_size = batch_size, shuffle=True, num_workers=2)
valDataloader = DataLoader(val, batch_size = batch_size, shuffle=False, num_workers=2)

# plt.plot(val.__getitem__(0)[0][:,0],tr.__getitem__(0)[0][:,1],'k')
# plt.plot(val.__getitem__(0)[1][:,0],tr.__getitem__(0)[1][:,1],'r')
# %%
#initialize network
lstm_encoder = model.lstm_encoder(args)
lstm_decoder = model.lstm_decoder(args)

n_epochs = 10

# %%
#initialize optimizer
learning_rate = 0.0002
encoder_optimizer = optim.Adam(lstm_encoder.parameters(), lr = learning_rate)
decoder_optimizer = optim.Adam(lstm_decoder.parameters(), lr = learning_rate)
criterion = nn.MSELoss()
# %%
#initialize loss
losses_tr =[]
losses_val = []

if device == "cuda":
    lstm_encoder = nn.DataParallel(lstm_encoder)
    lstm_decoder = nn.DataParallel(lstm_decoder)
lstm_encoder.to(device)
lstm_decoder.to(device)
# %%
lstm_encoder.load_state_dict(torch.load(f'traj_lstm_encoder_{obs_len}_{target_len}.tar'))
lstm_decoder.load_state_dict(torch.load(f'traj_lstm_decoder_{obs_len}_{target_len}.tar'))

# %%
n_epochs = 20
# %%
# save the best model, initialize only once
# minVal = math.inf
minVal = 10

# %%
with trange(n_epochs) as tr:
    
    for it in tr:

        ## Train:________________________________________________________________________________________________________
        lstm_encoder.train()
        lstm_decoder.train()

        batch_loss_tr = 0.
        
        lstm_encoder.zero_grad()
        lstm_decoder.zero_grad()
        tr_batch_count = 0.
        
        for i, data in enumerate(trDataloader):
            '''
            hist_batch_tr:      shape[batch_size, t_h, num_featurs]
            fut_batch_tr:       shape[batch_size, t_f, num_featurs]
            '''
        
            #hist_batch_tr: 
            hist_batch_tr,  fut_batch_tr = data
            #swap 0 and 1 dimension, hist_batch_tr: shape[t_h, batch_size, num_featurs]
            hist_batch_tr, fut_batch_tr = hist_batch_tr.permute(1, 0, 2), fut_batch_tr.permute(1, 0, 2)
            
            hist_batch_tr.to(device)
            fut_batch_tr.to(device)

            #zero the gradients
            encoder_optimizer.zero_grad()
            decoder_optimizer.zero_grad()

            #Initialize loss
            loss_tr = 0.

            # Initialize encoder hidden state
            batch_size = hist_batch_tr.shape[1]
            if device == "cuda":
                encoder_hidden = (torch.zeros(args["num_layers"], batch_size, args['hidden_size_enc']).to(device),
                                torch.zeros(args["num_layers"], batch_size, args['hidden_size_enc']).to(device)) 
            else:
                encoder_hidden = lstm_encoder.init_hidden(batch_size) 
                                
            #Encode observed trajectory 
            for ei in range(hist_batch_tr.shape[0]):
                encoder_input = hist_batch_tr[ei, :, :].unsqueeze(0)
                encoder_hidden = lstm_encoder(encoder_input, encoder_hidden)

            #Initialize decoder input with the last coordinate in encoder
            # decoder_input = encoder_input[:, :2]
            decoder_input = encoder_input
            #INitialize decoder hidden state as encoder hidden state
            decoder_hidden = encoder_hidden

            decoder_outputs_tr = torch.zeros(fut_batch_tr.shape).to(device)
            #decode hidden state in future trajectory
            for di in range(args['target_len']):
                decoder_output, decoder_hidden= lstm_decoder(decoder_input, decoder_hidden)
                decoder_outputs_tr[di, :, :] = decoder_output
                #update loss
                loss_tr += criterion(decoder_output.to(device), fut_batch_tr[di, :, :].unsqueeze(0).to(device))

                #use own predictions as inputs at next step
                decoder_input = decoder_output
            
            loss_tr = loss_tr / args['target_len']
            #compute the batch loss
            loss_tr.backward()
            batch_loss_tr += loss_tr.item()
            tr_batch_count += 1
            # losses_tr.append(batch_loss_tr/tr_batch_count)
            
            # #backpropagation and update weights
            encoder_optimizer.step()
            decoder_optimizer.step()
            
            a = nn.utils.clip_grad_norm_(lstm_encoder.parameters(), 100)
            b = nn.utils.clip_grad_norm_(lstm_decoder.parameters(), 100)
        
            # if i%100 == 99:
            #     # plot.hist_fut_pred_plot(hist_batch_tr.detach().numpy(), fut_batch_tr.detach().numpy(), fut_pred_tr.detach().numpy(), it, i, mode="train")
            #     #loss for epoch
            #     batch_loss_tr /= 100
            #     losses_tr.append(batch_loss_tr)
                
            #     #progress bar
            #     tr.set_postfix(loss="{0:.3f}".format(batch_loss_tr))
            #     print("Epoch no:",it+1,"| Epoch progress(%):", "| Avg train loss:",format(batch_loss_tr,'0.4f'))
            #     batch_loss_tr = 0.
        ## val:___________________________________________________________________________________________________________
        lstm_encoder.eval()
        lstm_decoder.eval()
        
        val_batch_count = 0
        val_loss = 0.
        predictions = {}
        with torch.no_grad():
            for i, data in enumerate(valDataloader):
                #select data
                hist_val, fut_val = data
                hist_val, fut_val = hist_val.permute(1, 0, 2), fut_val.permute(1, 0, 2)
                
                hist_val.to(device)
                fut_val.to(device)
                #Initialize encoder hidden state
                batch_size = hist_val.shape[1]
            
                if device == "cuda":
                    encoder_hidden = (torch.zeros(args["num_layers"], batch_size, args['hidden_size_enc']).to(device),
                                        torch.zeros(args["num_layers"], batch_size, args['hidden_size_enc']).to(device)) 
                else:
                    encoder_hidden = lstm_encoder.init_hidden(batch_size)      
                #Initialize loss
                loss_val = 0.

                #Encode observed trajectory
                for ei in range(hist_val.shape[0]):  
                    encoder_input = hist_val[ei, :, :].unsqueeze(0)
                    encoder_hidden = lstm_encoder(encoder_input, encoder_hidden)

                #Initialize decoder input with the last coordinate in encoder
                decoder_input = encoder_input
                #Initialize decoder hidden state as encoder hidden state
                decoder_hidden = encoder_hidden

                decoder_outputs_val = torch.zeros(fut_val.shape).to(device)
                #decode hidden state in future trajectory
                for di in range(args['target_len']):
                    decoder_output, decoder_hidden = lstm_decoder(decoder_input, decoder_hidden)
                    decoder_outputs_val[di, :, :] = decoder_output
                
                    #update loss
                    loss_val += criterion(decoder_output.to(device), fut_val[di, :, :].unsqueeze(0).to(device))

                    #use own predictions as inputs at next step
                    decoder_input = decoder_output

                #compute the loss
                loss_val /= args['target_len']
                val_loss += loss_val.item()
                val_batch_count += 1
                predictions[i] = decoder_outputs_val
        # plot.hist_fut_pred_plot(hist_val.detach().numpy(), fut_val.detach().numpy(), fut_pred_val.detach().numpy(), it, b)

        val_loss /= val_batch_count 
        losses_val.append(val_loss) 
        losses_tr.append(batch_loss_tr/tr_batch_count)
        # if it%5 == 4:
        print("Epoch no:",it+1,"| Epoch progress(%):", "| Avg train loss:",format(batch_loss_tr/tr_batch_count,'0.8f'), "| Avg validation loss:",format(val_loss,'0.8f'))
        
        # if val_loss < minVal:
        #     minVal = val_loss
        #     torch.save(lstm_encoder.state_dict(), f'traj_lstm_encoder_{obs_len}_{target_len}.tar')
        #     torch.save(lstm_decoder.state_dict(), f'traj_lstm_decoder_{obs_len}_{target_len}.tar')
        # print("Epoch", it+1, "complete.")

        if batch_loss_tr/tr_batch_count < minVal:
            minVal = batch_loss_tr/tr_batch_count
            torch.save(lstm_encoder.state_dict(), f'traj_lstm_encoder_{obs_len}_{target_len}.tar')
            torch.save(lstm_decoder.state_dict(), f'traj_lstm_decoder_{obs_len}_{target_len}.tar')
        


# %%
#plot on val data
decoder_outputs1 = decoder_outputs_val.to(device).detach().numpy()
fut_val1 = fut_val.to(device).detach().numpy()
hist_val1 = hist_val.to(device).detach().numpy()
plt.plot(hist_val1[:,:,0], hist_val1[:,:,1],color='0.7')
plt.plot(decoder_outputs1[:,:,0], decoder_outputs1[:,:,1],'r')
plt.plot(fut_val1[:,:,0], fut_val1[:,:,1],'k')
plt.ylim((-4,3))
plt.show()

# %%
#check train data
decoder_tr = decoder_outputs_tr.to(device).detach().numpy()
fut_tr1 = fut_batch_tr.to(device).detach().numpy()
hist_tr1 = hist_batch_tr.to(device).detach().numpy()
plt.plot(hist_tr1[:,:,0], hist_tr1[:,:,1],color='0.7')
plt.plot(decoder_tr[:,:,0], decoder_tr[:,:,1],'r')
plt.plot(fut_tr1[:,:,0], fut_tr1[:,:,1],'k')
# plt.ylim((-4,3))
plt.show()
# %%
criterion(decoder_outputs_val.to(device), fut_val.to(device))

# %%

# %%
plt.plot(range(len(losses_tr)), losses_tr, 'k', label = "train_error")
plt.plot(range(len(losses_val)), losses_val, 'r', label = "test_error")
plt.legend()
# plt.savefig("train_test_error_lr.png")
plt.show()

# %%
# pred = predictions[10].to(device).detach().numpy()
# gt = next(iter(valDataloader))[1].to(device).detach().numpy()
# plt.plot(hist_val1[:,:,0], hist_val1[:,:,1],color='0.7')

plt.plot(gt_hist[:,:,0], gt_hist[:,:,1],color='0.7')
plt.plot(pred[:,:,0], pred[:,:,1],'r')
plt.plot(gt_fut[:,:,0], gt_fut[:,:,1],'k')
plt.ylim((-3,3))
plt.show()
# %%
# on val dataset
import itertools
sample_at = 0
pred = predictions[sample_at].to(device).detach().numpy()

# k = int(np.floor(sample_at/batch_size))
#prediction and dataloader 0,1 dimensions swapped
k = sample_at
gt_fut = next(itertools.islice(valDataloader, k, k+1))[1].permute(1, 0, 2).to(device).detach().numpy()
gt_hist = next(itertools.islice(valDataloader, k, k+1))[0].permute(1, 0, 2).to(device).detach().numpy()


# %%
#denormalize the data
def get_normalized_to_map_coordinates(coords, translation, rotation):
    '''
    coords: np ndarray of shape [target_len, batch_size, 2]
    translation: list of len [batch_size]
    rotation: list of len [batch_size]
    '''
    abs_coords = []
    for i in range(coords.shape[1]):
        ls = LineString(coords[:, i, :])

        #rotate
        ls_rotate = rotate(ls, -rotation[i], origin=(0,0))

        #translate
        M_inv = [1,0,0,1,-translation[i][4], -translation[i][5]]

        ls_offset = affine_transform(ls_rotate, M_inv).coords[:]
        abs_coords.append(ls_offset)
    return np.array(abs_coords)

# %%
batch_size=8
translation = list(df1["translation"][sample_at*batch_size + 550 : sample_at*batch_size + 550 + batch_size])
rotation = list(df1["rotation"][sample_at*batch_size + 550 : sample_at*batch_size + 550 + batch_size])
pred_abs = get_normalized_to_map_coordinates(pred, translation, rotation)


# %%
#original
gt_val_658 = np.stack((df1["pos_x"].values[550].reshape(-1,1), df1["pos_y"].values[550].reshape(-1,1)), axis = 1)
plt.plot(gt_val_658[:,0], gt_val_658[:,1])

# %%
# normalized
plt.plot(df1["normalized_traj"].values[550][:,0], df1["normalized_traj"].values[550][:,1])
# %%
#denormalize
# %%
abs_pred = []
i = 0
# to_try = np.stack((df1["normalized_traj"].values[658][:,0], df1["normalized_traj"].values[658][:,1]), axis=-1)
to_try = pred[:,0,:]
ls = LineString(to_try)
ls_rotate = rotate(ls, -rotation[i], origin=(0,0))
M_inv = [1,0,0,1,-translation[i][4], -translation[i][5]]
ls_offset = affine_transform(ls_rotate, M_inv).coords[:]
abs_pred.append(ls_offset)
abs_pred = np.array(abs_pred)
plt.plot(abs_pred[:,:,0].flatten(), abs_pred[:,:,1].flatten())
# %%
for i in range(len(traj)):
  plt.plot(traj[i][:,0], traj[i][:,1], color='0.7')
  # plt.savefig(f"{save_dir}/traj_{i}.png")
  # plt.close()
# plt.plot(traj[0][:,0], traj[0][:,1], color='r')
plt.xlim((-120,-80))
plt.ylim((-130, -90))
# plt.savefig(f"{save_dir}/traj_example.png")

plt.plot(gt_val_658[:20,0], gt_val_658[:20,1],'k', label = "hist")
plt.plot(gt_val_658[20:,0], gt_val_658[20:,1],'b', label = "future")
plt.scatter(gt_val[20:,0], gt_val[20:,1],s=10., c='g', label = "ground truth", zorder=2)
plt.scatter(abs_pred[:,:,0].flatten(), abs_pred[:,:,1].flatten(), s=10., c='r', label = "prediction")
# plt.xlim((60,120))
# plt.ylim((0,20))
plt.legend()
plt.show()
# %%
save_dir = "figs/all"

for sample_at in range(10):

    pred = predictions[sample_at].to(device).detach().numpy()
    translation = list(df1["translation"][sample_at*batch_size + 550 : sample_at*batch_size + 550 + batch_size])
    rotation = list(df1["rotation"][sample_at*batch_size + 550 : sample_at*batch_size + 550 + batch_size])

    for i in range(batch_size):
        abs_pred = []
        to_try = pred[:,i,:]
        ls = LineString(to_try)
        ls_rotate = rotate(ls, -rotation[i], origin=(0,0))
        M_inv = [1,0,0,1,-translation[i][4], -translation[i][5]]
        ls_offset = affine_transform(ls_rotate, M_inv).coords[:]
        abs_pred.append(ls_offset)
        abs_pred = np.array(abs_pred)
        gt_val = np.stack((df1["pos_x"].values[550+sample_at*batch_size+i].reshape(-1,1), df1["pos_y"].values[550+sample_at*batch_size+i].reshape(-1,1)), axis = 1)
        for j in range(len(traj)):
            plt.plot(traj[j][:,0], traj[j][:,1], color='0.7', linewidth=3, zorder=1)
        plt.scatter(gt_val[20:,0], gt_val[20:,1],s=10., c='g', label = "future", zorder=2)
        plt.scatter(abs_pred[:,:,0].flatten(), abs_pred[:,:,1].flatten(), s=10., c='r', label = "pred", zorder=2)
        plt.xlim((-102,-88))
        plt.ylim((-125, -105))
        plt.xticks([])
        plt.yticks([])
        # plt.legend(loc='upper right')
        plt.savefig(f"{save_dir}/{550+sample_at*batch_size+i}.png")
        plt.close('all')
# %%
###calculate MSE on each timestamp
batch_size = 36
# mse_val = 0
# counts = 0
for sample_at in range(1,2):

    pred = predictions[sample_at].to(device).detach().numpy()
    translation = list(df1["translation"][sample_at*batch_size + 550 : sample_at*batch_size + 550 + batch_size])
    rotation = list(df1["rotation"][sample_at*batch_size + 550 : sample_at*batch_size + 550 + batch_size])

    for i in range(batch_size):
        abs_pred = []
        to_try = pred[:,i,:]
        ls = LineString(to_try)
        ls_rotate = rotate(ls, -rotation[i], origin=(0,0))
        M_inv = [1,0,0,1,-translation[i][4], -translation[i][5]]
        ls_offset = affine_transform(ls_rotate, M_inv).coords[:]
        abs_pred.append(ls_offset)
        abs_pred = np.array(abs_pred)
        gt_val = np.stack((df1["pos_x"].values[550+sample_at*batch_size+i].reshape(-1,1), df1["pos_y"].values[550+sample_at*batch_size+i].reshape(-1,1)), axis = 1)
        # for j in range(len(traj)):
        #     plt.plot(traj[j][:,0], traj[j][:,1], color='0.7', linewidth=3, zorder=1)
        # plt.scatter(gt_val[20:,0], gt_val[20:,1],s=10., c='g', label = "future", zorder=2)
        # plt.scatter(abs_pred[:,:,0].flatten(), abs_pred[:,:,1].flatten(), s=10., c='r', label = "pred", zorder=2)
        # plt.xlim((-102,-88))
        # plt.ylim((-125, -105))
        # plt.xticks([])
        # plt.yticks([])
        # # plt.legend(loc='upper right')
        # plt.savefig(f"{save_dir}/{550+sample_at*batch_size+i}.png")
        # plt.close('all')
        mse_val += ((abs_pred[0] - gt_val[obs_len:,].squeeze())**2).sum(axis=1)
        counts += 1
# %%
mse_val /= counts
# %%
np.savetxt('toy_example/results/mse_50_50.csv', mse_val, delimiter=",")
# %%
plt.plot(mse_val, label="obs50_fut50")
plt.legend()
plt.savefig("toy_example/results/figs/obs50_fut50.png")

# %%
mse_30_50 = np.loadtxt('toy_example/results/mse_30_50.csv')
# %%
